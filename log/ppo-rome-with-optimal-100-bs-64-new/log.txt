Logging to ./log/ppo-rome-with-optimal-100-bs-64-new

 ---------------- Iteration 0 ----------------
Sampling trajectories from environment ...
Sampling spend time: 601.4221894741058s
Processing trajectories ...
Processing spend time: 1649.5944848060608s
Baselien algorithms: 19.21900510787964s
Updating policies ....
Update spend time: 230.0273461341858s
-------------------------------------------
| Itr                     | 0             |
| average always migra... | -1.38e+03     |
| average never migrat... | -1.28e+03     |
| average random reward:  | -2.24e+03     |
| average reward:         | -2948.33      |
| batch size              | 160           |
| entropy loss:           | 121.41        |
| optimal migrate rewa... | -0            |
| policy loss:            | 1.76          |
| value loss:             | 15.0          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 1 ----------------
Sampling trajectories from environment ...
Sampling spend time: 488.2135157585144s
Processing trajectories ...
Processing spend time: 1673.0114090442657s
Baselien algorithms: 19.16597032546997s
Updating policies ....
Update spend time: 241.56194400787354s
-------------------------------------------
| Itr                     | 1             |
| average always migra... | -1.38e+03     |
| average never migrat... | -1.28e+03     |
| average random reward:  | -2.24e+03     |
| average reward:         | -2896.63      |
| batch size              | 160           |
| entropy loss:           | 121.65        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.01         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 2 ----------------
Sampling trajectories from environment ...
Sampling spend time: 586.703647851944s
Processing trajectories ...
Processing spend time: 1680.33553481102s
Baselien algorithms: 19.096999883651733s
Updating policies ....
Update spend time: 258.8548889160156s
-------------------------------------------
| Itr                     | 2             |
| average always migra... | -1.38e+03     |
| average never migrat... | -1.28e+03     |
| average random reward:  | -2.24e+03     |
| average reward:         | -2863.86      |
| batch size              | 160           |
| entropy loss:           | 121.5         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.13         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 3 ----------------
Sampling trajectories from environment ...
Sampling spend time: 525.4424583911896s
Processing trajectories ...
Processing spend time: 1674.7533342838287s
Baselien algorithms: 19.612233638763428s
Updating policies ....
Update spend time: 281.1363718509674s
-------------------------------------------
| Itr                     | 3             |
| average always migra... | -1.38e+03     |
| average never migrat... | -1.28e+03     |
| average random reward:  | -2.24e+03     |
| average reward:         | -2805.88      |
| batch size              | 160           |
| entropy loss:           | 120.71        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.16         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 4 ----------------
Sampling trajectories from environment ...
Sampling spend time: 585.6892628669739s
Processing trajectories ...
Processing spend time: 1676.2936902046204s
Baselien algorithms: 19.058085441589355s
Updating policies ....
Update spend time: 287.54087829589844s
-------------------------------------------
| Itr                     | 4             |
| average always migra... | -1.38e+03     |
| average never migrat... | -1.28e+03     |
| average random reward:  | -2.24e+03     |
| average reward:         | -2711.35      |
| batch size              | 160           |
| entropy loss:           | 119.35        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.17         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 5 ----------------
Sampling trajectories from environment ...
Sampling spend time: 744.1895668506622s
Processing trajectories ...
Processing spend time: 1672.2625603675842s
Baselien algorithms: 26.806402683258057s
Updating policies ....
Update spend time: 241.11314845085144s
-------------------------------------------
| Itr                     | 5             |
| average always migra... | -1.38e+03     |
| average never migrat... | -1.28e+03     |
| average random reward:  | -2.24e+03     |
| average reward:         | -2647.86      |
| batch size              | 160           |
| entropy loss:           | 117.5         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.16         |
| value loss:             | 15.0          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 6 ----------------
Sampling trajectories from environment ...
Sampling spend time: 690.647664308548s
Processing trajectories ...

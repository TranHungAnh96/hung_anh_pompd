Logging to ./log/ppo-rome-with-optimal-100-bs-64-new-no-rnn

 ---------------- Iteration 0 ----------------
Sampling trajectories from environment ...
Sampling spend time: 359.56218242645264s
Processing trajectories ...
Processing spend time: 2.990905523300171s
Baselien algorithms: 17.280174493789673s
Updating policies ....
Update spend time: 10.46938157081604s
-------------------------------------------
| Itr                     | 0             |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1356.01      |
| batch size              | 480           |
| entropy loss:           | 1.87          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.23          |
| value loss:             | 19.02         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 1 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.33319449424744s
Processing trajectories ...
Processing spend time: 2.979234457015991s
Baselien algorithms: 17.256035804748535s
Updating policies ....
Update spend time: 10.48862361907959s
-------------------------------------------
| Itr                     | 1             |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1146.03      |
| batch size              | 480           |
| entropy loss:           | 0.72          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.04          |
| value loss:             | 6.57          |
-------------------------------------------

 ---------------- Iteration 2 ----------------
Sampling trajectories from environment ...
Sampling spend time: 363.01671743392944s
Processing trajectories ...
Processing spend time: 3.093278646469116s
Baselien algorithms: 17.369076013565063s
Updating policies ....
Update spend time: 10.501083850860596s
-------------------------------------------
| Itr                     | 2             |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1066.68      |
| batch size              | 480           |
| entropy loss:           | 0.4           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.02         |
| value loss:             | 5.57          |
-------------------------------------------

 ---------------- Iteration 3 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.10889959335327s
Processing trajectories ...
Processing spend time: 3.0608174800872803s
Baselien algorithms: 16.77065372467041s
Updating policies ....
Update spend time: 10.489248514175415s
-------------------------------------------
| Itr                     | 3             |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1048.27      |
| batch size              | 480           |
| entropy loss:           | 0.25          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 5.59          |
-------------------------------------------

 ---------------- Iteration 4 ----------------
Sampling trajectories from environment ...
Sampling spend time: 359.9953553676605s
Processing trajectories ...
Processing spend time: 2.9971158504486084s
Baselien algorithms: 17.055986642837524s
Updating policies ....
Update spend time: 10.469722032546997s
-------------------------------------------
| Itr                     | 4             |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1040.0       |
| batch size              | 480           |
| entropy loss:           | 0.19          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 6.75          |
-------------------------------------------

 ---------------- Iteration 5 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.7418646812439s
Processing trajectories ...
Processing spend time: 2.93509840965271s
Baselien algorithms: 16.83956551551819s
Updating policies ....
Update spend time: 10.477542638778687s
-------------------------------------------
| Itr                     | 5             |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1038.05      |
| batch size              | 480           |
| entropy loss:           | 0.16          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 5.26          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 6 ----------------
Sampling trajectories from environment ...
Sampling spend time: 365.7323200702667s
Processing trajectories ...
Processing spend time: 2.89039945602417s
Baselien algorithms: 17.015217542648315s
Updating policies ....
Update spend time: 10.490992784500122s
-------------------------------------------
| Itr                     | 6             |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1036.41      |
| batch size              | 480           |
| entropy loss:           | 0.15          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.52          |
-------------------------------------------

 ---------------- Iteration 7 ----------------
Sampling trajectories from environment ...
Sampling spend time: 363.30054545402527s
Processing trajectories ...
Processing spend time: 3.025334596633911s
Baselien algorithms: 17.37720274925232s
Updating policies ....
Update spend time: 10.499505043029785s
-------------------------------------------
| Itr                     | 7             |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1032.84      |
| batch size              | 480           |
| entropy loss:           | 0.14          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 14.54         |
-------------------------------------------

 ---------------- Iteration 8 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.04812598228455s
Processing trajectories ...
Processing spend time: 2.9626402854919434s
Baselien algorithms: 16.943822860717773s
Updating policies ....
Update spend time: 10.48560118675232s
-------------------------------------------
| Itr                     | 8             |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1032.13      |
| batch size              | 480           |
| entropy loss:           | 0.05          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 6.57          |
-------------------------------------------

 ---------------- Iteration 9 ----------------
Sampling trajectories from environment ...
Sampling spend time: 364.4098472595215s
Processing trajectories ...
Processing spend time: 3.0486855506896973s
Baselien algorithms: 17.171691179275513s
Updating policies ....
Update spend time: 10.49797534942627s
-------------------------------------------
| Itr                     | 9             |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1030.3       |
| batch size              | 480           |
| entropy loss:           | 0.05          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 6.67          |
-------------------------------------------

 ---------------- Iteration 10 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.3634033203125s
Processing trajectories ...
Processing spend time: 3.153653621673584s
Baselien algorithms: 17.090261936187744s
Updating policies ....
Update spend time: 10.454834699630737s
-------------------------------------------
| Itr                     | 10            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1029.88      |
| batch size              | 480           |
| entropy loss:           | 0.05          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 6.11          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 11 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.251482963562s
Processing trajectories ...
Processing spend time: 3.0047447681427s
Baselien algorithms: 16.748257875442505s
Updating policies ....
Update spend time: 10.49393105506897s
-------------------------------------------
| Itr                     | 11            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1029.56      |
| batch size              | 480           |
| entropy loss:           | 0.05          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 7.29          |
-------------------------------------------

 ---------------- Iteration 12 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.4960615634918s
Processing trajectories ...
Processing spend time: 2.999497890472412s
Baselien algorithms: 16.983975887298584s
Updating policies ....
Update spend time: 10.484956979751587s
-------------------------------------------
| Itr                     | 12            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1029.32      |
| batch size              | 480           |
| entropy loss:           | 0.04          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 10.69         |
-------------------------------------------

 ---------------- Iteration 13 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.60270738601685s
Processing trajectories ...
Processing spend time: 2.9940812587738037s
Baselien algorithms: 17.28035593032837s
Updating policies ....
Update spend time: 10.529587984085083s
-------------------------------------------
| Itr                     | 13            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1028.48      |
| batch size              | 480           |
| entropy loss:           | 0.04          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 6.25          |
-------------------------------------------

 ---------------- Iteration 14 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.18154978752136s
Processing trajectories ...
Processing spend time: 2.9589591026306152s
Baselien algorithms: 17.341469049453735s
Updating policies ....
Update spend time: 10.480697631835938s
-------------------------------------------
| Itr                     | 14            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1028.25      |
| batch size              | 480           |
| entropy loss:           | 0.03          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 6.07          |
-------------------------------------------

 ---------------- Iteration 15 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.6960277557373s
Processing trajectories ...
Processing spend time: 2.9729673862457275s
Baselien algorithms: 17.05990171432495s
Updating policies ....
Update spend time: 10.471223831176758s
-------------------------------------------
| Itr                     | 15            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1028.36      |
| batch size              | 480           |
| entropy loss:           | 0.02          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.74          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 16 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.4084334373474s
Processing trajectories ...
Processing spend time: 3.0585646629333496s
Baselien algorithms: 17.179240226745605s
Updating policies ....
Update spend time: 10.519160747528076s
-------------------------------------------
| Itr                     | 16            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1027.24      |
| batch size              | 480           |
| entropy loss:           | 0.03          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.09          |
-------------------------------------------

 ---------------- Iteration 17 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.30789709091187s
Processing trajectories ...
Processing spend time: 3.0247738361358643s
Baselien algorithms: 16.86704683303833s
Updating policies ....
Update spend time: 10.494951009750366s
-------------------------------------------
| Itr                     | 17            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1027.65      |
| batch size              | 480           |
| entropy loss:           | 0.05          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 11.12         |
-------------------------------------------

 ---------------- Iteration 18 ----------------
Sampling trajectories from environment ...
Sampling spend time: 359.89382100105286s
Processing trajectories ...
Processing spend time: 3.0435423851013184s
Baselien algorithms: 17.26319456100464s
Updating policies ....
Update spend time: 10.471024751663208s
-------------------------------------------
| Itr                     | 18            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.39      |
| batch size              | 480           |
| entropy loss:           | 0.01          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 8.04          |
-------------------------------------------

 ---------------- Iteration 19 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.4316210746765s
Processing trajectories ...
Processing spend time: 2.9969494342803955s
Baselien algorithms: 17.128276348114014s
Updating policies ....
Update spend time: 10.536311626434326s
-------------------------------------------
| Itr                     | 19            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.86      |
| batch size              | 480           |
| entropy loss:           | 0.01          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 6.76          |
-------------------------------------------

 ---------------- Iteration 20 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.3931429386139s
Processing trajectories ...
Processing spend time: 2.918623924255371s
Baselien algorithms: 17.203108310699463s
Updating policies ....
Update spend time: 10.53457498550415s
-------------------------------------------
| Itr                     | 20            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.31      |
| batch size              | 480           |
| entropy loss:           | 0.01          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.28          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 21 ----------------
Sampling trajectories from environment ...
Sampling spend time: 357.4579019546509s
Processing trajectories ...
Processing spend time: 2.9987974166870117s
Baselien algorithms: 16.926116228103638s
Updating policies ....
Update spend time: 10.488892793655396s
-------------------------------------------
| Itr                     | 21            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.55      |
| batch size              | 480           |
| entropy loss:           | 0.01          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 6.35          |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.49770426750183s
Processing trajectories ...
Processing spend time: 2.996056079864502s
Baselien algorithms: 17.394643783569336s
Updating policies ....
Update spend time: 10.54713225364685s
-------------------------------------------
| Itr                     | 22            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1026.11      |
| batch size              | 480           |
| entropy loss:           | 0.01          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 7.9           |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Sampling trajectories from environment ...
Sampling spend time: 366.0878555774689s
Processing trajectories ...
Processing spend time: 2.9913785457611084s
Baselien algorithms: 17.175116539001465s
Updating policies ....
Update spend time: 10.499799489974976s
-------------------------------------------
| Itr                     | 23            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1026.48      |
| batch size              | 480           |
| entropy loss:           | 0.01          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 6.09          |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Sampling trajectories from environment ...
Sampling spend time: 365.9312665462494s
Processing trajectories ...
Processing spend time: 3.0020503997802734s
Baselien algorithms: 17.20617437362671s
Updating policies ....
Update spend time: 10.462136030197144s
-------------------------------------------
| Itr                     | 24            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1026.51      |
| batch size              | 480           |
| entropy loss:           | 0.01          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 8.49          |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Sampling trajectories from environment ...
Sampling spend time: 357.8630542755127s
Processing trajectories ...
Processing spend time: 2.98075532913208s
Baselien algorithms: 17.216459274291992s
Updating policies ....
Update spend time: 10.522234201431274s
-------------------------------------------
| Itr                     | 25            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1024.72      |
| batch size              | 480           |
| entropy loss:           | 0.01          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 14.82         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 26 ----------------
Sampling trajectories from environment ...
Sampling spend time: 359.2030851840973s
Processing trajectories ...
Processing spend time: 2.9996118545532227s
Baselien algorithms: 16.863540410995483s
Updating policies ....
Update spend time: 10.506181716918945s
-------------------------------------------
| Itr                     | 26            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.25      |
| batch size              | 480           |
| entropy loss:           | 0.01          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.64          |
-------------------------------------------

 ---------------- Iteration 27 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.84041595458984s
Processing trajectories ...
Processing spend time: 3.2082016468048096s
Baselien algorithms: 17.29294729232788s
Updating policies ....
Update spend time: 10.532299995422363s
-------------------------------------------
| Itr                     | 27            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.94      |
| batch size              | 480           |
| entropy loss:           | 0.02          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 8.88          |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.60458970069885s
Processing trajectories ...
Processing spend time: 3.0012600421905518s
Baselien algorithms: 16.913341999053955s
Updating policies ....
Update spend time: 10.534181594848633s
-------------------------------------------
| Itr                     | 28            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.09      |
| batch size              | 480           |
| entropy loss:           | 0.01          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.98          |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Sampling trajectories from environment ...
Sampling spend time: 366.31460404396057s
Processing trajectories ...
Processing spend time: 2.9854795932769775s
Baselien algorithms: 17.210702419281006s
Updating policies ....
Update spend time: 10.531301498413086s
-------------------------------------------
| Itr                     | 29            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1024.7       |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 6.87          |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Sampling trajectories from environment ...
Sampling spend time: 369.98106122016907s
Processing trajectories ...
Processing spend time: 2.9934585094451904s
Baselien algorithms: 17.239526748657227s
Updating policies ....
Update spend time: 10.532773971557617s
-------------------------------------------
| Itr                     | 30            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1024.79      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.4           |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 31 ----------------
Sampling trajectories from environment ...
Sampling spend time: 364.6840009689331s
Processing trajectories ...
Processing spend time: 3.072371006011963s
Baselien algorithms: 16.83219051361084s
Updating policies ....
Update spend time: 10.523438692092896s
-------------------------------------------
| Itr                     | 31            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1026.2       |
| batch size              | 480           |
| entropy loss:           | 0.01          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.58          |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.1548388004303s
Processing trajectories ...
Processing spend time: 3.1483888626098633s
Baselien algorithms: 17.151727437973022s
Updating policies ....
Update spend time: 10.517398834228516s
-------------------------------------------
| Itr                     | 32            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.8       |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 7.67          |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.13690519332886s
Processing trajectories ...
Processing spend time: 2.9370052814483643s
Baselien algorithms: 16.955017805099487s
Updating policies ....
Update spend time: 10.56656289100647s
-------------------------------------------
| Itr                     | 33            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.15      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 6.73          |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Sampling trajectories from environment ...
Sampling spend time: 364.99414443969727s
Processing trajectories ...
Processing spend time: 3.0643885135650635s
Baselien algorithms: 16.886441946029663s
Updating policies ....
Update spend time: 10.526251792907715s
-------------------------------------------
| Itr                     | 34            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1024.75      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 6.55          |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.91650223731995s
Processing trajectories ...
Processing spend time: 3.02150821685791s
Baselien algorithms: 16.89099144935608s
Updating policies ....
Update spend time: 10.553582191467285s
-------------------------------------------
| Itr                     | 35            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.06      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 6.49          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 36 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.4152171611786s
Processing trajectories ...
Processing spend time: 3.0690574645996094s
Baselien algorithms: 16.89681839942932s
Updating policies ....
Update spend time: 10.543579339981079s
-------------------------------------------
| Itr                     | 36            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.98      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 10.35         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.3467757701874s
Processing trajectories ...
Processing spend time: 3.1239490509033203s
Baselien algorithms: 17.183619022369385s
Updating policies ....
Update spend time: 10.532235145568848s
-------------------------------------------
| Itr                     | 37            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.92      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 5.46          |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.3770682811737s
Processing trajectories ...
Processing spend time: 3.0033626556396484s
Baselien algorithms: 17.01715588569641s
Updating policies ....
Update spend time: 10.512105703353882s
-------------------------------------------
| Itr                     | 38            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.03      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 5.43          |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.9942715167999s
Processing trajectories ...
Processing spend time: 2.966580629348755s
Baselien algorithms: 17.172650814056396s
Updating policies ....
Update spend time: 10.526226997375488s
-------------------------------------------
| Itr                     | 39            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.04      |
| batch size              | 480           |
| entropy loss:           | 0.03          |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 65.04         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Sampling trajectories from environment ...
Sampling spend time: 363.3463761806488s
Processing trajectories ...
Processing spend time: 2.966764450073242s
Baselien algorithms: 17.136124849319458s
Updating policies ....
Update spend time: 10.508176565170288s
-------------------------------------------
| Itr                     | 40            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.6       |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 7.03          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 41 ----------------
Sampling trajectories from environment ...
Sampling spend time: 363.32467126846313s
Processing trajectories ...
Processing spend time: 2.9110937118530273s
Baselien algorithms: 16.90179753303528s
Updating policies ....
Update spend time: 10.545628786087036s
-------------------------------------------
| Itr                     | 41            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.33      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 6.98          |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.11530470848083s
Processing trajectories ...
Processing spend time: 2.9749536514282227s
Baselien algorithms: 17.07923936843872s
Updating policies ....
Update spend time: 10.520543813705444s
-------------------------------------------
| Itr                     | 42            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.69      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 13.15         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.7362105846405s
Processing trajectories ...
Processing spend time: 2.984807252883911s
Baselien algorithms: 17.08013677597046s
Updating policies ....
Update spend time: 10.537482023239136s
-------------------------------------------
| Itr                     | 43            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.64      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 8.18          |
-------------------------------------------

 ---------------- Iteration 44 ----------------
Sampling trajectories from environment ...
Sampling spend time: 357.928875207901s
Processing trajectories ...
Processing spend time: 3.065294027328491s
Baselien algorithms: 16.910057306289673s
Updating policies ....
Update spend time: 10.548940420150757s
-------------------------------------------
| Itr                     | 44            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.72      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.84          |
-------------------------------------------

 ---------------- Iteration 45 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.278683423996s
Processing trajectories ...
Processing spend time: 3.0430688858032227s
Baselien algorithms: 17.510595083236694s
Updating policies ....
Update spend time: 10.524952411651611s
-------------------------------------------
| Itr                     | 45            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.85      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.54          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 46 ----------------
Sampling trajectories from environment ...
Sampling spend time: 363.1947412490845s
Processing trajectories ...
Processing spend time: 2.986811399459839s
Baselien algorithms: 17.06983232498169s
Updating policies ....
Update spend time: 10.513474225997925s
-------------------------------------------
| Itr                     | 46            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.75      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.48          |
-------------------------------------------

 ---------------- Iteration 47 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.4365453720093s
Processing trajectories ...
Processing spend time: 3.0613107681274414s
Baselien algorithms: 16.867429494857788s
Updating policies ....
Update spend time: 10.475804328918457s
-------------------------------------------
| Itr                     | 47            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.66      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.43          |
-------------------------------------------

 ---------------- Iteration 48 ----------------
Sampling trajectories from environment ...
Sampling spend time: 364.3465600013733s
Processing trajectories ...
Processing spend time: 2.9822356700897217s
Baselien algorithms: 16.80160164833069s
Updating policies ....
Update spend time: 10.501366376876831s
-------------------------------------------
| Itr                     | 48            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1024.24      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.36          |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.33706402778625s
Processing trajectories ...
Processing spend time: 3.079744338989258s
Baselien algorithms: 17.254111289978027s
Updating policies ....
Update spend time: 10.518648624420166s
-------------------------------------------
| Itr                     | 49            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.29      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.35          |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.7564158439636s
Processing trajectories ...
Processing spend time: 3.0510904788970947s
Baselien algorithms: 16.678892374038696s
Updating policies ....
Update spend time: 10.536410808563232s
-------------------------------------------
| Itr                     | 50            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.45      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.31          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 51 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.5863311290741s
Processing trajectories ...
Processing spend time: 2.912431001663208s
Baselien algorithms: 16.781262636184692s
Updating policies ....
Update spend time: 10.523772954940796s
-------------------------------------------
| Itr                     | 51            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.75      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.3           |
-------------------------------------------

 ---------------- Iteration 52 ----------------
Sampling trajectories from environment ...
Sampling spend time: 364.27704405784607s
Processing trajectories ...
Processing spend time: 2.9799282550811768s
Baselien algorithms: 17.243746519088745s
Updating policies ....
Update spend time: 10.563349485397339s
-------------------------------------------
| Itr                     | 52            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1026.2       |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.29          |
-------------------------------------------

 ---------------- Iteration 53 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.6147720813751s
Processing trajectories ...
Processing spend time: 3.0416831970214844s
Baselien algorithms: 17.37746238708496s
Updating policies ....
Update spend time: 10.521421909332275s
-------------------------------------------
| Itr                     | 53            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.75      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.24          |
-------------------------------------------

 ---------------- Iteration 54 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.28442645072937s
Processing trajectories ...
Processing spend time: 2.9696907997131348s
Baselien algorithms: 16.88716697692871s
Updating policies ....
Update spend time: 10.553590536117554s
-------------------------------------------
| Itr                     | 54            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.37      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.22          |
-------------------------------------------

 ---------------- Iteration 55 ----------------
Sampling trajectories from environment ...
Sampling spend time: 359.80147194862366s
Processing trajectories ...
Processing spend time: 3.0519840717315674s
Baselien algorithms: 16.996970176696777s
Updating policies ....
Update spend time: 10.494416952133179s
-------------------------------------------
| Itr                     | 55            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.91      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.21          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 56 ----------------
Sampling trajectories from environment ...
Sampling spend time: 364.83451771736145s
Processing trajectories ...
Processing spend time: 3.0585734844207764s
Baselien algorithms: 17.099294424057007s
Updating policies ....
Update spend time: 10.542418956756592s
-------------------------------------------
| Itr                     | 56            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.39      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.21          |
-------------------------------------------

 ---------------- Iteration 57 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.3927752971649s
Processing trajectories ...
Processing spend time: 3.0006585121154785s
Baselien algorithms: 17.297602891921997s
Updating policies ....
Update spend time: 10.532564878463745s
-------------------------------------------
| Itr                     | 57            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.75      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.18          |
-------------------------------------------

 ---------------- Iteration 58 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.58894205093384s
Processing trajectories ...
Processing spend time: 2.9101855754852295s
Baselien algorithms: 17.0631902217865s
Updating policies ....
Update spend time: 10.53456974029541s
-------------------------------------------
| Itr                     | 58            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.07      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.16          |
-------------------------------------------

 ---------------- Iteration 59 ----------------
Sampling trajectories from environment ...
Sampling spend time: 357.7491703033447s
Processing trajectories ...
Processing spend time: 2.9964797496795654s
Baselien algorithms: 17.33354640007019s
Updating policies ....
Update spend time: 10.512840509414673s
-------------------------------------------
| Itr                     | 59            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1024.88      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 9.15          |
-------------------------------------------

 ---------------- Iteration 60 ----------------
Sampling trajectories from environment ...
Sampling spend time: 359.0045120716095s
Processing trajectories ...
Processing spend time: 3.0224549770355225s
Baselien algorithms: 17.130146980285645s
Updating policies ....
Update spend time: 10.556445598602295s
-------------------------------------------
| Itr                     | 60            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1024.19      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.12          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 61 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.97352504730225s
Processing trajectories ...
Processing spend time: 3.0147979259490967s
Baselien algorithms: 16.824573040008545s
Updating policies ....
Update spend time: 10.543806076049805s
-------------------------------------------
| Itr                     | 61            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.02      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 9.1           |
-------------------------------------------

 ---------------- Iteration 62 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.3716869354248s
Processing trajectories ...
Processing spend time: 3.0126655101776123s
Baselien algorithms: 17.147433042526245s
Updating policies ....
Update spend time: 10.534473180770874s
-------------------------------------------
| Itr                     | 62            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1026.04      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.08          |
-------------------------------------------

 ---------------- Iteration 63 ----------------
Sampling trajectories from environment ...
Sampling spend time: 365.6358587741852s
Processing trajectories ...
Processing spend time: 3.026461601257324s
Baselien algorithms: 17.257580280303955s
Updating policies ....
Update spend time: 10.553234100341797s
-------------------------------------------
| Itr                     | 63            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.48      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 9.06          |
-------------------------------------------

 ---------------- Iteration 64 ----------------
Sampling trajectories from environment ...
Sampling spend time: 359.7206199169159s
Processing trajectories ...
Processing spend time: 3.0185844898223877s
Baselien algorithms: 16.890773057937622s
Updating policies ....
Update spend time: 10.531022071838379s
-------------------------------------------
| Itr                     | 64            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.29      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 9.04          |
-------------------------------------------

 ---------------- Iteration 65 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.791898727417s
Processing trajectories ...
Processing spend time: 2.9746735095977783s
Baselien algorithms: 17.205371618270874s
Updating policies ....
Update spend time: 10.538813352584839s
-------------------------------------------
| Itr                     | 65            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.21      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 9.02          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 66 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.587917804718s
Processing trajectories ...
Processing spend time: 2.992800712585449s
Baselien algorithms: 16.90174388885498s
Updating policies ....
Update spend time: 10.523385286331177s
-------------------------------------------
| Itr                     | 66            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1026.2       |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.99          |
-------------------------------------------

 ---------------- Iteration 67 ----------------
Sampling trajectories from environment ...
Sampling spend time: 364.09299063682556s
Processing trajectories ...
Processing spend time: 2.983945608139038s
Baselien algorithms: 17.41214346885681s
Updating policies ....
Update spend time: 10.567642450332642s
-------------------------------------------
| Itr                     | 67            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.19      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.97          |
-------------------------------------------

 ---------------- Iteration 68 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.0503044128418s
Processing trajectories ...
Processing spend time: 2.983851194381714s
Baselien algorithms: 17.001359224319458s
Updating policies ....
Update spend time: 10.535145282745361s
-------------------------------------------
| Itr                     | 68            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1026.31      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.95          |
-------------------------------------------

 ---------------- Iteration 69 ----------------
Sampling trajectories from environment ...
Sampling spend time: 364.25822019577026s
Processing trajectories ...
Processing spend time: 2.9749960899353027s
Baselien algorithms: 16.9945011138916s
Updating policies ....
Update spend time: 10.536413192749023s
-------------------------------------------
| Itr                     | 69            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.06      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.92          |
-------------------------------------------

 ---------------- Iteration 70 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.2476043701172s
Processing trajectories ...
Processing spend time: 2.9219930171966553s
Baselien algorithms: 16.930299520492554s
Updating policies ....
Update spend time: 10.56254768371582s
-------------------------------------------
| Itr                     | 70            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1024.73      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.88          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 71 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.7897756099701s
Processing trajectories ...
Processing spend time: 3.0502941608428955s
Baselien algorithms: 17.249630451202393s
Updating policies ....
Update spend time: 10.505162954330444s
-------------------------------------------
| Itr                     | 71            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.36      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.86          |
-------------------------------------------

 ---------------- Iteration 72 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.39080905914307s
Processing trajectories ...
Processing spend time: 2.9736058712005615s
Baselien algorithms: 17.36308741569519s
Updating policies ....
Update spend time: 10.552538633346558s
-------------------------------------------
| Itr                     | 72            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1027.18      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.85          |
-------------------------------------------

 ---------------- Iteration 73 ----------------
Sampling trajectories from environment ...
Sampling spend time: 363.095130443573s
Processing trajectories ...
Processing spend time: 3.137244939804077s
Baselien algorithms: 16.74995470046997s
Updating policies ....
Update spend time: 10.543823957443237s
-------------------------------------------
| Itr                     | 73            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1026.7       |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.82          |
-------------------------------------------

 ---------------- Iteration 74 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.4182724952698s
Processing trajectories ...
Processing spend time: 2.954841136932373s
Baselien algorithms: 16.724053382873535s
Updating policies ....
Update spend time: 10.609100580215454s
-------------------------------------------
| Itr                     | 74            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.9       |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.79          |
-------------------------------------------

 ---------------- Iteration 75 ----------------
Sampling trajectories from environment ...
Sampling spend time: 363.64389395713806s
Processing trajectories ...
Processing spend time: 2.987581968307495s
Baselien algorithms: 16.982001543045044s
Updating policies ....
Update spend time: 10.562755823135376s
-------------------------------------------
| Itr                     | 75            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1024.44      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.75          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 76 ----------------
Sampling trajectories from environment ...
Sampling spend time: 363.35523319244385s
Processing trajectories ...
Processing spend time: 3.041940689086914s
Baselien algorithms: 17.034884691238403s
Updating policies ....
Update spend time: 10.574289083480835s
-------------------------------------------
| Itr                     | 76            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1024.71      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.72          |
-------------------------------------------

 ---------------- Iteration 77 ----------------
Sampling trajectories from environment ...
Sampling spend time: 363.42166662216187s
Processing trajectories ...
Processing spend time: 3.0231614112854004s
Baselien algorithms: 17.04106903076172s
Updating policies ....
Update spend time: 10.61101245880127s
-------------------------------------------
| Itr                     | 77            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.94      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.7           |
-------------------------------------------

 ---------------- Iteration 78 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.77726221084595s
Processing trajectories ...
Processing spend time: 2.9663357734680176s
Baselien algorithms: 16.974806547164917s
Updating policies ....
Update spend time: 10.596372365951538s
-------------------------------------------
| Itr                     | 78            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.32      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.67          |
-------------------------------------------

 ---------------- Iteration 79 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.96918964385986s
Processing trajectories ...
Processing spend time: 3.0662484169006348s
Baselien algorithms: 17.016337156295776s
Updating policies ....
Update spend time: 10.558456420898438s
-------------------------------------------
| Itr                     | 79            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.13      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.65          |
-------------------------------------------

 ---------------- Iteration 80 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.56296849250793s
Processing trajectories ...
Processing spend time: 3.061079740524292s
Baselien algorithms: 16.788925170898438s
Updating policies ....
Update spend time: 10.58558964729309s
-------------------------------------------
| Itr                     | 80            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.51      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.62          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 81 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.5744652748108s
Processing trajectories ...
Processing spend time: 3.1465280055999756s
Baselien algorithms: 17.133047342300415s
Updating policies ....
Update spend time: 10.585020780563354s
-------------------------------------------
| Itr                     | 81            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1024.61      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.58          |
-------------------------------------------

 ---------------- Iteration 82 ----------------
Sampling trajectories from environment ...
Sampling spend time: 363.5934422016144s
Processing trajectories ...
Processing spend time: 2.9803028106689453s
Baselien algorithms: 17.07637357711792s
Updating policies ....
Update spend time: 10.59625792503357s
-------------------------------------------
| Itr                     | 82            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.58      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.57          |
-------------------------------------------

 ---------------- Iteration 83 ----------------
Sampling trajectories from environment ...
Sampling spend time: 363.8471519947052s
Processing trajectories ...
Processing spend time: 3.1384544372558594s
Baselien algorithms: 17.11276388168335s
Updating policies ....
Update spend time: 10.562960863113403s
-------------------------------------------
| Itr                     | 83            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1024.29      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.53          |
-------------------------------------------

 ---------------- Iteration 84 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.2098078727722s
Processing trajectories ...
Processing spend time: 3.0853052139282227s
Baselien algorithms: 16.88465929031372s
Updating policies ....
Update spend time: 10.59781002998352s
-------------------------------------------
| Itr                     | 84            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.29      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.52          |
-------------------------------------------

 ---------------- Iteration 85 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.60902976989746s
Processing trajectories ...
Processing spend time: 2.938613176345825s
Baselien algorithms: 16.962465047836304s
Updating policies ....
Update spend time: 10.566960334777832s
-------------------------------------------
| Itr                     | 85            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.22      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.47          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 86 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.3680098056793s
Processing trajectories ...
Processing spend time: 3.105905532836914s
Baselien algorithms: 17.158267498016357s
Updating policies ....
Update spend time: 10.59575343132019s
-------------------------------------------
| Itr                     | 86            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.08      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.46          |
-------------------------------------------

 ---------------- Iteration 87 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.92709589004517s
Processing trajectories ...
Processing spend time: 2.996706008911133s
Baselien algorithms: 17.100263118743896s
Updating policies ....
Update spend time: 10.555029153823853s
-------------------------------------------
| Itr                     | 87            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.36      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.44          |
-------------------------------------------

 ---------------- Iteration 88 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.31098890304565s
Processing trajectories ...
Processing spend time: 2.9818992614746094s
Baselien algorithms: 16.811121702194214s
Updating policies ....
Update spend time: 10.578385591506958s
-------------------------------------------
| Itr                     | 88            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1026.19      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.41          |
-------------------------------------------

 ---------------- Iteration 89 ----------------
Sampling trajectories from environment ...
Sampling spend time: 357.5274107456207s
Processing trajectories ...
Processing spend time: 2.9689934253692627s
Baselien algorithms: 16.780502796173096s
Updating policies ....
Update spend time: 10.55780816078186s
-------------------------------------------
| Itr                     | 89            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.31      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.37          |
-------------------------------------------

 ---------------- Iteration 90 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.9768922328949s
Processing trajectories ...
Processing spend time: 3.0789787769317627s
Baselien algorithms: 16.79179811477661s
Updating policies ....
Update spend time: 10.546132564544678s
-------------------------------------------
| Itr                     | 90            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.17      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.34          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 91 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.8657274246216s
Processing trajectories ...
Processing spend time: 2.9125821590423584s
Baselien algorithms: 17.326070070266724s
Updating policies ....
Update spend time: 10.53302812576294s
-------------------------------------------
| Itr                     | 91            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.75      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.33          |
-------------------------------------------

 ---------------- Iteration 92 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.1129720211029s
Processing trajectories ...
Processing spend time: 3.0181643962860107s
Baselien algorithms: 17.107609748840332s
Updating policies ....
Update spend time: 10.571815013885498s
-------------------------------------------
| Itr                     | 92            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.39      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.31          |
-------------------------------------------

 ---------------- Iteration 93 ----------------
Sampling trajectories from environment ...
Sampling spend time: 363.1006555557251s
Processing trajectories ...
Processing spend time: 2.956819534301758s
Baselien algorithms: 16.67389440536499s
Updating policies ....
Update spend time: 10.532209873199463s
-------------------------------------------
| Itr                     | 93            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.32      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.28          |
-------------------------------------------

 ---------------- Iteration 94 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.62377643585205s
Processing trajectories ...
Processing spend time: 3.0332374572753906s
Baselien algorithms: 16.88694977760315s
Updating policies ....
Update spend time: 10.56067442893982s
-------------------------------------------
| Itr                     | 94            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.42      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.26          |
-------------------------------------------

 ---------------- Iteration 95 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.42124605178833s
Processing trajectories ...
Processing spend time: 3.037409543991089s
Baselien algorithms: 17.188907623291016s
Updating policies ....
Update spend time: 10.553675889968872s
-------------------------------------------
| Itr                     | 95            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1024.94      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.24          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 96 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.1479260921478s
Processing trajectories ...
Processing spend time: 2.999009847640991s
Baselien algorithms: 17.14210081100464s
Updating policies ....
Update spend time: 10.546231508255005s
-------------------------------------------
| Itr                     | 96            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1026.26      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.22          |
-------------------------------------------

 ---------------- Iteration 97 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.0268177986145s
Processing trajectories ...
Processing spend time: 2.9330358505249023s
Baselien algorithms: 16.816808223724365s
Updating policies ....
Update spend time: 10.54961109161377s
-------------------------------------------
| Itr                     | 97            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1026.3       |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.21          |
-------------------------------------------

 ---------------- Iteration 98 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.0070173740387s
Processing trajectories ...
Processing spend time: 3.069502830505371s
Baselien algorithms: 16.893504858016968s
Updating policies ....
Update spend time: 10.586658477783203s
-------------------------------------------
| Itr                     | 98            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1026.24      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 8.18          |
-------------------------------------------

 ---------------- Iteration 99 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.7732973098755s
Processing trajectories ...
Processing spend time: 3.0443177223205566s
Baselien algorithms: 17.117172956466675s
Updating policies ....
Update spend time: 10.568800449371338s
-------------------------------------------
| Itr                     | 99            |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1023.74      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.15          |
-------------------------------------------

 ---------------- Iteration 100 ----------------
Sampling trajectories from environment ...
Sampling spend time: 354.7351369857788s
Processing trajectories ...
Processing spend time: 2.9260740280151367s
Baselien algorithms: 17.120224237442017s
Updating policies ....
Update spend time: 10.583507537841797s
-------------------------------------------
| Itr                     | 100           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.39      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.14          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 101 ----------------
Sampling trajectories from environment ...
Sampling spend time: 357.7506582736969s
Processing trajectories ...
Processing spend time: 3.0779147148132324s
Baselien algorithms: 16.82932686805725s
Updating policies ....
Update spend time: 10.567911624908447s
-------------------------------------------
| Itr                     | 101           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1024.8       |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.12          |
-------------------------------------------

 ---------------- Iteration 102 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.9114270210266s
Processing trajectories ...
Processing spend time: 3.0991759300231934s
Baselien algorithms: 16.949002981185913s
Updating policies ....
Update spend time: 10.609456300735474s
-------------------------------------------
| Itr                     | 102           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1024.89      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.11          |
-------------------------------------------

 ---------------- Iteration 103 ----------------
Sampling trajectories from environment ...
Sampling spend time: 360.8454842567444s
Processing trajectories ...
Processing spend time: 2.8712010383605957s
Baselien algorithms: 16.8530490398407s
Updating policies ....
Update spend time: 10.565761804580688s
-------------------------------------------
| Itr                     | 103           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.44      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.11          |
-------------------------------------------

 ---------------- Iteration 104 ----------------
Sampling trajectories from environment ...
Sampling spend time: 357.1812541484833s
Processing trajectories ...
Processing spend time: 3.029182195663452s
Baselien algorithms: 16.848626852035522s
Updating policies ....
Update spend time: 10.575111865997314s
-------------------------------------------
| Itr                     | 104           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.52      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.08          |
-------------------------------------------

 ---------------- Iteration 105 ----------------
Sampling trajectories from environment ...
Sampling spend time: 354.9804058074951s
Processing trajectories ...
Processing spend time: 2.990226984024048s
Baselien algorithms: 16.70191192626953s
Updating policies ....
Update spend time: 10.569838047027588s
-------------------------------------------
| Itr                     | 105           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1026.48      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.08          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 106 ----------------
Sampling trajectories from environment ...
Sampling spend time: 355.6064922809601s
Processing trajectories ...
Processing spend time: 3.0047097206115723s
Baselien algorithms: 16.668596744537354s
Updating policies ....
Update spend time: 10.598427295684814s
-------------------------------------------
| Itr                     | 106           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.45      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.0           |
| value loss:             | 8.06          |
-------------------------------------------

 ---------------- Iteration 107 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.4954433441162s
Processing trajectories ...
Processing spend time: 3.051792860031128s
Baselien algorithms: 16.74447536468506s
Updating policies ....
Update spend time: 10.613630533218384s
-------------------------------------------
| Itr                     | 107           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.03      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.04          |
-------------------------------------------

 ---------------- Iteration 108 ----------------
Sampling trajectories from environment ...
Sampling spend time: 352.7307324409485s
Processing trajectories ...
Processing spend time: 2.9917757511138916s
Baselien algorithms: 16.83558440208435s
Updating policies ....
Update spend time: 10.55095362663269s
-------------------------------------------
| Itr                     | 108           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.01      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.01          |
-------------------------------------------

 ---------------- Iteration 109 ----------------
Sampling trajectories from environment ...
Sampling spend time: 359.0634436607361s
Processing trajectories ...
Processing spend time: 3.0635554790496826s
Baselien algorithms: 17.03225827217102s
Updating policies ....
Update spend time: 10.567605018615723s
-------------------------------------------
| Itr                     | 109           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.87      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 8.0           |
-------------------------------------------

 ---------------- Iteration 110 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.38268542289734s
Processing trajectories ...
Processing spend time: 2.9870097637176514s
Baselien algorithms: 16.89473533630371s
Updating policies ....
Update spend time: 10.591444492340088s
-------------------------------------------
| Itr                     | 110           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.01      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 7.99          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 111 ----------------
Sampling trajectories from environment ...
Sampling spend time: 361.23949337005615s
Processing trajectories ...
Processing spend time: 3.0337448120117188s
Baselien algorithms: 17.225969552993774s
Updating policies ....
Update spend time: 10.560664415359497s
-------------------------------------------
| Itr                     | 111           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.12      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 7.97          |
-------------------------------------------

 ---------------- Iteration 112 ----------------
Sampling trajectories from environment ...
Sampling spend time: 357.89813566207886s
Processing trajectories ...
Processing spend time: 2.9917304515838623s
Baselien algorithms: 16.483847856521606s
Updating policies ....
Update spend time: 10.545780897140503s
-------------------------------------------
| Itr                     | 112           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1025.03      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 7.95          |
-------------------------------------------

 ---------------- Iteration 113 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.9662163257599s
Processing trajectories ...
Processing spend time: 2.9759557247161865s
Baselien algorithms: 17.00956439971924s
Updating policies ....
Update spend time: 10.563871383666992s
-------------------------------------------
| Itr                     | 113           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.4       |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 7.94          |
-------------------------------------------

 ---------------- Iteration 114 ----------------
Sampling trajectories from environment ...
Sampling spend time: 358.8140082359314s
Processing trajectories ...
Processing spend time: 3.078329563140869s
Baselien algorithms: 17.066623210906982s
Updating policies ....
Update spend time: 10.604930400848389s
-------------------------------------------
| Itr                     | 114           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.41      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 7.91          |
-------------------------------------------

 ---------------- Iteration 115 ----------------
Sampling trajectories from environment ...
Sampling spend time: 364.38094115257263s
Processing trajectories ...
Processing spend time: 3.0204882621765137s
Baselien algorithms: 16.966522693634033s
Updating policies ....
Update spend time: 10.566089153289795s
-------------------------------------------
| Itr                     | 115           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1024.81      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 7.9           |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 116 ----------------
Sampling trajectories from environment ...
Sampling spend time: 357.5592484474182s
Processing trajectories ...
Processing spend time: 2.981984853744507s
Baselien algorithms: 17.130722284317017s
Updating policies ....
Update spend time: 10.572307109832764s
-------------------------------------------
| Itr                     | 116           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1025.7       |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 7.88          |
-------------------------------------------

 ---------------- Iteration 117 ----------------
Sampling trajectories from environment ...
Sampling spend time: 357.4156279563904s
Processing trajectories ...
Processing spend time: 3.0251615047454834s
Baselien algorithms: 16.611271619796753s
Updating policies ....
Update spend time: 10.609440326690674s
-------------------------------------------
| Itr                     | 117           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.44e+03     |
| average reward:         | -1026.11      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 7.86          |
-------------------------------------------

 ---------------- Iteration 118 ----------------
Sampling trajectories from environment ...
Sampling spend time: 357.2231249809265s
Processing trajectories ...
Processing spend time: 3.063101053237915s
Baselien algorithms: 17.1376473903656s
Updating policies ....
Update spend time: 10.608959674835205s
-------------------------------------------
| Itr                     | 118           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1026.12      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 7.84          |
-------------------------------------------

 ---------------- Iteration 119 ----------------
Sampling trajectories from environment ...
Sampling spend time: 362.94807386398315s
Processing trajectories ...
Processing spend time: 2.99337100982666s
Baselien algorithms: 16.855135679244995s
Updating policies ....
Update spend time: 10.621599674224854s
-------------------------------------------
| Itr                     | 119           |
| average always migra... | -1.57e+03     |
| average never migrat... | -1.48e+03     |
| average random reward:  | -2.45e+03     |
| average reward:         | -1024.93      |
| batch size              | 480           |
| entropy loss:           | 0.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 7.81          |
-------------------------------------------

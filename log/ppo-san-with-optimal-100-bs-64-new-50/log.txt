Logging to ./log/ppo-san-with-optimal-100-bs-64-new-50

 ---------------- Iteration 0 ----------------
Sampling trajectories from environment ...
Sampling spend time: 302.4003884792328s
Processing trajectories ...
Processing spend time: 583.9792819023132s
Baselien algorithms: 19.77673649787903s
Updating policies ....
Update spend time: 75.09954738616943s
-------------------------------------------
| Itr                     | 0             |
| average always migra... | -1.56e+03     |
| average never migrat... | -1.47e+03     |
| average random reward:  | -2.24e+03     |
| average reward:         | -1157.14      |
| batch size              | 160           |
| entropy loss:           | 120.24        |
| optimal migrate rewa... | -0            |
| policy loss:            | 0.73          |
| value loss:             | 15.01         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 1 ----------------
Sampling trajectories from environment ...
Sampling spend time: 311.83814096450806s
Processing trajectories ...
Processing spend time: 554.5363430976868s
Baselien algorithms: 19.019142150878906s
Updating policies ....
Update spend time: 70.22975826263428s
-------------------------------------------
| Itr                     | 1             |
| average always migra... | -1.56e+03     |
| average never migrat... | -1.47e+03     |
| average random reward:  | -2.24e+03     |
| average reward:         | -1089.86      |
| batch size              | 160           |
| entropy loss:           | 118.45        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.76         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 2 ----------------
Sampling trajectories from environment ...
Sampling spend time: 279.19915413856506s
Processing trajectories ...
Processing spend time: 556.5972738265991s
Baselien algorithms: 19.174075603485107s
Updating policies ....
Update spend time: 70.85110306739807s
-------------------------------------------
| Itr                     | 2             |
| average always migra... | -1.56e+03     |
| average never migrat... | -1.47e+03     |
| average random reward:  | -2.24e+03     |
| average reward:         | -1037.65      |
| batch size              | 160           |
| entropy loss:           | 115.72        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.91         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 3 ----------------
Sampling trajectories from environment ...
Sampling spend time: 273.7099595069885s
Processing trajectories ...
Processing spend time: 561.102635383606s
Baselien algorithms: 19.09106421470642s
Updating policies ....
Update spend time: 70.99360370635986s
-------------------------------------------
| Itr                     | 3             |
| average always migra... | -1.56e+03     |
| average never migrat... | -1.47e+03     |
| average random reward:  | -2.24e+03     |
| average reward:         | -988.66       |
| batch size              | 160           |
| entropy loss:           | 112.78        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.79         |
| value loss:             | 15.01         |
-------------------------------------------

 ---------------- Iteration 4 ----------------
Sampling trajectories from environment ...
Sampling spend time: 275.8861794471741s
Processing trajectories ...
Processing spend time: 559.199892282486s
Baselien algorithms: 19.225001335144043s
Updating policies ....
Update spend time: 70.92828607559204s
-------------------------------------------
| Itr                     | 4             |
| average always migra... | -1.56e+03     |
| average never migrat... | -1.47e+03     |
| average random reward:  | -2.24e+03     |
| average reward:         | -945.47       |
| batch size              | 160           |
| entropy loss:           | 109.27        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.75         |
| value loss:             | 14.97         |
-------------------------------------------

 ---------------- Iteration 5 ----------------
Sampling trajectories from environment ...
Sampling spend time: 276.92384123802185s
Processing trajectories ...
Processing spend time: 557.2008337974548s
Baselien algorithms: 19.314003229141235s
Updating policies ....
Update spend time: 70.34638905525208s
-------------------------------------------
| Itr                     | 5             |
| average always migra... | -1.56e+03     |
| average never migrat... | -1.47e+03     |
| average random reward:  | -2.24e+03     |
| average reward:         | -908.96       |
| batch size              | 160           |
| entropy loss:           | 105.67        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.69         |
| value loss:             | 15.09         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 6 ----------------
Sampling trajectories from environment ...
Sampling spend time: 273.31779170036316s
Processing trajectories ...
Processing spend time: 554.0219037532806s
Baselien algorithms: 19.16360855102539s
Updating policies ....
Update spend time: 70.79560852050781s
-------------------------------------------
| Itr                     | 6             |
| average always migra... | -1.56e+03     |
| average never migrat... | -1.47e+03     |
| average random reward:  | -2.24e+03     |
| average reward:         | -874.4        |
| batch size              | 160           |
| entropy loss:           | 101.62        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.69         |
| value loss:             | 15.04         |
-------------------------------------------

 ---------------- Iteration 7 ----------------
Sampling trajectories from environment ...
Sampling spend time: 275.7101767063141s
Processing trajectories ...

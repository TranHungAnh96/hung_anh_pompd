Logging to ./log/ppo-san-with-optimal-100-bs-64-new-50

 ---------------- Iteration 0 ----------------
Sampling trajectories from environment ...
Sampling spend time: 326.44647550582886s
Processing trajectories ...
Processing spend time: 572.1560826301575s
Baselien algorithms: 19.152161359786987s
Updating policies ....
Update spend time: 72.44654059410095s
-------------------------------------------
| Itr                     | 0             |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -3128.37      |
| batch size              | 160           |
| entropy loss:           | 121.09        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 14.99         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 1 ----------------
Sampling trajectories from environment ...
Sampling spend time: 336.27674436569214s
Processing trajectories ...
Processing spend time: 560.9871411323547s
Baselien algorithms: 19.149993896484375s
Updating policies ....
Update spend time: 68.36657810211182s
-------------------------------------------
| Itr                     | 1             |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -3046.54      |
| batch size              | 160           |
| entropy loss:           | 120.27        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.19         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 2 ----------------
Sampling trajectories from environment ...
Sampling spend time: 291.00220251083374s
Processing trajectories ...
Processing spend time: 549.8928003311157s
Baselien algorithms: 19.097059965133667s
Updating policies ....
Update spend time: 68.39920353889465s
-------------------------------------------
| Itr                     | 2             |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -2925.89      |
| batch size              | 160           |
| entropy loss:           | 118.78        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.22         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 3 ----------------
Sampling trajectories from environment ...
Sampling spend time: 290.98327231407166s
Processing trajectories ...
Processing spend time: 553.7959015369415s
Baselien algorithms: 19.20255136489868s
Updating policies ....
Update spend time: 68.75461387634277s
-------------------------------------------
| Itr                     | 3             |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -2839.96      |
| batch size              | 160           |
| entropy loss:           | 116.91        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.23         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 4 ----------------
Sampling trajectories from environment ...
Sampling spend time: 290.39886474609375s
Processing trajectories ...
Processing spend time: 551.6770932674408s
Baselien algorithms: 19.176007986068726s
Updating policies ....
Update spend time: 68.74512147903442s
-------------------------------------------
| Itr                     | 4             |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -2730.48      |
| batch size              | 160           |
| entropy loss:           | 114.74        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.24         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 5 ----------------
Sampling trajectories from environment ...
Sampling spend time: 289.1547861099243s
Processing trajectories ...
Processing spend time: 555.8893110752106s
Baselien algorithms: 19.124027490615845s
Updating policies ....
Update spend time: 68.43443846702576s
-------------------------------------------
| Itr                     | 5             |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -2625.56      |
| batch size              | 160           |
| entropy loss:           | 112.12        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.25         |
| value loss:             | 15.0          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 6 ----------------
Sampling trajectories from environment ...
Sampling spend time: 288.9242422580719s
Processing trajectories ...
Processing spend time: 553.1648941040039s
Baselien algorithms: 19.140006065368652s
Updating policies ....
Update spend time: 69.2879536151886s
-------------------------------------------
| Itr                     | 6             |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -2528.51      |
| batch size              | 160           |
| entropy loss:           | 108.86        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.26         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 7 ----------------
Sampling trajectories from environment ...
Sampling spend time: 288.02561950683594s
Processing trajectories ...
Processing spend time: 554.8585247993469s
Baselien algorithms: 19.158029794692993s
Updating policies ....
Update spend time: 68.89408302307129s
-------------------------------------------
| Itr                     | 7             |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -2421.01      |
| batch size              | 160           |
| entropy loss:           | 105.13        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.27         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 8 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.8496651649475s
Processing trajectories ...
Processing spend time: 555.9277122020721s
Baselien algorithms: 19.142536878585815s
Updating policies ....
Update spend time: 68.59711122512817s
-------------------------------------------
| Itr                     | 8             |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -2314.6       |
| batch size              | 160           |
| entropy loss:           | 100.78        |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.25         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 9 ----------------
Sampling trajectories from environment ...
Sampling spend time: 288.196537733078s
Processing trajectories ...
Processing spend time: 557.5052938461304s
Baselien algorithms: 19.05860686302185s
Updating policies ....
Update spend time: 68.92200207710266s
-------------------------------------------
| Itr                     | 9             |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -2225.88      |
| batch size              | 160           |
| entropy loss:           | 96.27         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.26         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 10 ----------------
Sampling trajectories from environment ...
Sampling spend time: 288.32121753692627s
Processing trajectories ...
Processing spend time: 558.0496680736542s
Baselien algorithms: 19.242963314056396s
Updating policies ....
Update spend time: 69.10305666923523s
-------------------------------------------
| Itr                     | 10            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -2141.39      |
| batch size              | 160           |
| entropy loss:           | 91.64         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.24         |
| value loss:             | 15.0          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 11 ----------------
Sampling trajectories from environment ...
Sampling spend time: 290.60163021087646s
Processing trajectories ...
Processing spend time: 554.1265728473663s
Baselien algorithms: 19.131000757217407s
Updating policies ....
Update spend time: 68.43652200698853s
-------------------------------------------
| Itr                     | 11            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -2062.48      |
| batch size              | 160           |
| entropy loss:           | 86.55         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.24         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 12 ----------------
Sampling trajectories from environment ...
Sampling spend time: 289.1166400909424s
Processing trajectories ...
Processing spend time: 551.8504064083099s
Baselien algorithms: 19.110029697418213s
Updating policies ....
Update spend time: 69.41904735565186s
-------------------------------------------
| Itr                     | 12            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1979.32      |
| batch size              | 160           |
| entropy loss:           | 81.62         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.23         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 13 ----------------
Sampling trajectories from environment ...
Sampling spend time: 289.9544429779053s
Processing trajectories ...
Processing spend time: 554.7205951213837s
Baselien algorithms: 19.12103033065796s
Updating policies ....
Update spend time: 68.47306704521179s
-------------------------------------------
| Itr                     | 13            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1914.28      |
| batch size              | 160           |
| entropy loss:           | 76.67         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.23         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 14 ----------------
Sampling trajectories from environment ...
Sampling spend time: 285.6895823478699s
Processing trajectories ...
Processing spend time: 550.3600730895996s
Baselien algorithms: 19.21306300163269s
Updating policies ....
Update spend time: 68.5095567703247s
-------------------------------------------
| Itr                     | 14            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1844.14      |
| batch size              | 160           |
| entropy loss:           | 72.24         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.22         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 15 ----------------
Sampling trajectories from environment ...
Sampling spend time: 288.59611439704895s
Processing trajectories ...
Processing spend time: 551.9537396430969s
Baselien algorithms: 19.09366011619568s
Updating policies ....
Update spend time: 69.14506411552429s
-------------------------------------------
| Itr                     | 15            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1792.28      |
| batch size              | 160           |
| entropy loss:           | 68.79         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.21         |
| value loss:             | 15.0          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 16 ----------------
Sampling trajectories from environment ...
Sampling spend time: 289.9940800666809s
Processing trajectories ...
Processing spend time: 554.5542147159576s
Baselien algorithms: 19.11969518661499s
Updating policies ....
Update spend time: 68.23598766326904s
-------------------------------------------
| Itr                     | 16            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1731.09      |
| batch size              | 160           |
| entropy loss:           | 64.69         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.21         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 17 ----------------
Sampling trajectories from environment ...
Sampling spend time: 289.96549701690674s
Processing trajectories ...
Processing spend time: 553.3947989940643s
Baselien algorithms: 19.10257315635681s
Updating policies ....
Update spend time: 68.93063950538635s
-------------------------------------------
| Itr                     | 17            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1687.68      |
| batch size              | 160           |
| entropy loss:           | 60.38         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.23         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 18 ----------------
Sampling trajectories from environment ...
Sampling spend time: 289.2582597732544s
Processing trajectories ...
Processing spend time: 555.9503269195557s
Baselien algorithms: 19.233540773391724s
Updating policies ....
Update spend time: 69.23814105987549s
-------------------------------------------
| Itr                     | 18            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1626.59      |
| batch size              | 160           |
| entropy loss:           | 56.06         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.23         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 19 ----------------
Sampling trajectories from environment ...
Sampling spend time: 289.4116744995117s
Processing trajectories ...
Processing spend time: 555.6489655971527s
Baselien algorithms: 19.17703127861023s
Updating policies ....
Update spend time: 68.91386818885803s
-------------------------------------------
| Itr                     | 19            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1575.08      |
| batch size              | 160           |
| entropy loss:           | 51.82         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.25         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 20 ----------------
Sampling trajectories from environment ...
Sampling spend time: 289.75866055488586s
Processing trajectories ...
Processing spend time: 554.4948420524597s
Baselien algorithms: 19.161993741989136s
Updating policies ....
Update spend time: 69.86309742927551s
-------------------------------------------
| Itr                     | 20            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1517.87      |
| batch size              | 160           |
| entropy loss:           | 47.5          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.26         |
| value loss:             | 15.0          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 21 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.05716848373413s
Processing trajectories ...
Processing spend time: 552.4433562755585s
Baselien algorithms: 19.214035749435425s
Updating policies ....
Update spend time: 69.19096875190735s
-------------------------------------------
| Itr                     | 21            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1462.43      |
| batch size              | 160           |
| entropy loss:           | 43.17         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.29         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 22 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.9388859272003s
Processing trajectories ...
Processing spend time: 557.19380235672s
Baselien algorithms: 19.256001234054565s
Updating policies ....
Update spend time: 69.34746479988098s
-------------------------------------------
| Itr                     | 22            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1415.19      |
| batch size              | 160           |
| entropy loss:           | 38.59         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.29         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 23 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.5067732334137s
Processing trajectories ...
Processing spend time: 553.5695898532867s
Baselien algorithms: 19.10421657562256s
Updating policies ....
Update spend time: 68.99309635162354s
-------------------------------------------
| Itr                     | 23            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1358.39      |
| batch size              | 160           |
| entropy loss:           | 33.7          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.29         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 24 ----------------
Sampling trajectories from environment ...
Sampling spend time: 284.8516945838928s
Processing trajectories ...
Processing spend time: 556.9135580062866s
Baselien algorithms: 19.14102864265442s
Updating policies ....
Update spend time: 69.81364226341248s
-------------------------------------------
| Itr                     | 24            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1315.64      |
| batch size              | 160           |
| entropy loss:           | 29.35         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.26         |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 25 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.4090881347656s
Processing trajectories ...
Processing spend time: 552.54429936409s
Baselien algorithms: 19.164000272750854s
Updating policies ....
Update spend time: 68.32454705238342s
-------------------------------------------
| Itr                     | 25            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1275.71      |
| batch size              | 160           |
| entropy loss:           | 25.36         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.22         |
| value loss:             | 15.01         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 26 ----------------
Sampling trajectories from environment ...
Sampling spend time: 283.98884868621826s
Processing trajectories ...
Processing spend time: 556.7969882488251s
Baselien algorithms: 19.056997060775757s
Updating policies ....
Update spend time: 68.5757737159729s
-------------------------------------------
| Itr                     | 26            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1245.68      |
| batch size              | 160           |
| entropy loss:           | 21.78         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.21         |
| value loss:             | 14.99         |
-------------------------------------------

 ---------------- Iteration 27 ----------------
Sampling trajectories from environment ...
Sampling spend time: 283.8923850059509s
Processing trajectories ...
Processing spend time: 550.651734828949s
Baselien algorithms: 19.094172954559326s
Updating policies ....
Update spend time: 68.12129473686218s
-------------------------------------------
| Itr                     | 27            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1222.14      |
| batch size              | 160           |
| entropy loss:           | 18.7          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.18         |
| value loss:             | 15.02         |
-------------------------------------------

 ---------------- Iteration 28 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.68039727211s
Processing trajectories ...
Processing spend time: 554.2255337238312s
Baselien algorithms: 19.18900227546692s
Updating policies ....
Update spend time: 68.8129768371582s
-------------------------------------------
| Itr                     | 28            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1199.74      |
| batch size              | 160           |
| entropy loss:           | 15.99         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.15         |
| value loss:             | 15.01         |
-------------------------------------------

 ---------------- Iteration 29 ----------------
Sampling trajectories from environment ...
Sampling spend time: 285.3574402332306s
Processing trajectories ...
Processing spend time: 552.3513503074646s
Baselien algorithms: 19.13103437423706s
Updating policies ....
Update spend time: 69.34868550300598s
-------------------------------------------
| Itr                     | 29            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1184.8       |
| batch size              | 160           |
| entropy loss:           | 13.6          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.14         |
| value loss:             | 14.99         |
-------------------------------------------

 ---------------- Iteration 30 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.28968143463135s
Processing trajectories ...
Processing spend time: 552.7586386203766s
Baselien algorithms: 19.103049516677856s
Updating policies ....
Update spend time: 68.37117648124695s
-------------------------------------------
| Itr                     | 30            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1171.87      |
| batch size              | 160           |
| entropy loss:           | 11.54         |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.11         |
| value loss:             | 15.0          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 31 ----------------
Sampling trajectories from environment ...
Sampling spend time: 283.5097436904907s
Processing trajectories ...
Processing spend time: 556.3712115287781s
Baselien algorithms: 19.14499807357788s
Updating policies ....
Update spend time: 69.05778169631958s
-------------------------------------------
| Itr                     | 31            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1157.89      |
| batch size              | 160           |
| entropy loss:           | 9.75          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.09         |
| value loss:             | 15.01         |
-------------------------------------------

 ---------------- Iteration 32 ----------------
Sampling trajectories from environment ...
Sampling spend time: 282.77698135375977s
Processing trajectories ...
Processing spend time: 555.1711919307709s
Baselien algorithms: 19.11202907562256s
Updating policies ....
Update spend time: 68.58564805984497s
-------------------------------------------
| Itr                     | 32            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1155.31      |
| batch size              | 160           |
| entropy loss:           | 8.27          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.08         |
| value loss:             | 15.09         |
-------------------------------------------

 ---------------- Iteration 33 ----------------
Sampling trajectories from environment ...
Sampling spend time: 281.5087592601776s
Processing trajectories ...
Processing spend time: 551.0103459358215s
Baselien algorithms: 19.090599536895752s
Updating policies ....
Update spend time: 68.34161472320557s
-------------------------------------------
| Itr                     | 33            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1145.13      |
| batch size              | 160           |
| entropy loss:           | 7.0           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.06         |
| value loss:             | 15.07         |
-------------------------------------------

 ---------------- Iteration 34 ----------------
Sampling trajectories from environment ...
Sampling spend time: 283.7534763813019s
Processing trajectories ...
Processing spend time: 553.4894738197327s
Baselien algorithms: 19.105013847351074s
Updating policies ....
Update spend time: 69.01478266716003s
-------------------------------------------
| Itr                     | 34            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1136.77      |
| batch size              | 160           |
| entropy loss:           | 5.87          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.05         |
| value loss:             | 14.99         |
-------------------------------------------

 ---------------- Iteration 35 ----------------
Sampling trajectories from environment ...
Sampling spend time: 283.1367824077606s
Processing trajectories ...
Processing spend time: 553.4103615283966s
Baselien algorithms: 19.09697151184082s
Updating policies ....
Update spend time: 68.74124765396118s
-------------------------------------------
| Itr                     | 35            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1130.99      |
| batch size              | 160           |
| entropy loss:           | 4.95          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.04         |
| value loss:             | 15.09         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 36 ----------------
Sampling trajectories from environment ...
Sampling spend time: 281.8630383014679s
Processing trajectories ...
Processing spend time: 554.1003348827362s
Baselien algorithms: 19.085479497909546s
Updating policies ....
Update spend time: 69.01558351516724s
-------------------------------------------
| Itr                     | 36            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1128.66      |
| batch size              | 160           |
| entropy loss:           | 4.2           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.03         |
| value loss:             | 15.27         |
-------------------------------------------

 ---------------- Iteration 37 ----------------
Sampling trajectories from environment ...
Sampling spend time: 282.88961696624756s
Processing trajectories ...
Processing spend time: 553.2586224079132s
Baselien algorithms: 19.142046689987183s
Updating policies ....
Update spend time: 68.38455986976624s
-------------------------------------------
| Itr                     | 37            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1131.89      |
| batch size              | 160           |
| entropy loss:           | 3.59          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.03         |
| value loss:             | 15.13         |
-------------------------------------------

 ---------------- Iteration 38 ----------------
Sampling trajectories from environment ...
Sampling spend time: 285.7091763019562s
Processing trajectories ...
Processing spend time: 551.6840078830719s
Baselien algorithms: 19.061035871505737s
Updating policies ....
Update spend time: 68.2770004272461s
-------------------------------------------
| Itr                     | 38            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1126.85      |
| batch size              | 160           |
| entropy loss:           | 3.04          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.02         |
| value loss:             | 15.22         |
-------------------------------------------

 ---------------- Iteration 39 ----------------
Sampling trajectories from environment ...
Sampling spend time: 284.0768485069275s
Processing trajectories ...
Processing spend time: 553.3264374732971s
Baselien algorithms: 19.162002563476562s
Updating policies ....
Update spend time: 68.97805762290955s
-------------------------------------------
| Itr                     | 39            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1123.95      |
| batch size              | 160           |
| entropy loss:           | 2.52          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.02         |
| value loss:             | 15.15         |
-------------------------------------------

 ---------------- Iteration 40 ----------------
Sampling trajectories from environment ...
Sampling spend time: 282.4080755710602s
Processing trajectories ...
Processing spend time: 556.0515995025635s
Baselien algorithms: 19.102978229522705s
Updating policies ....
Update spend time: 69.22037363052368s
-------------------------------------------
| Itr                     | 40            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1122.61      |
| batch size              | 160           |
| entropy loss:           | 2.09          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.02         |
| value loss:             | 15.05         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 41 ----------------
Sampling trajectories from environment ...
Sampling spend time: 282.276070356369s
Processing trajectories ...
Processing spend time: 554.2877852916718s
Baselien algorithms: 19.231000661849976s
Updating policies ....
Update spend time: 68.76563596725464s
-------------------------------------------
| Itr                     | 41            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1116.81      |
| batch size              | 160           |
| entropy loss:           | 1.77          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.01         |
| value loss:             | 15.18         |
-------------------------------------------

 ---------------- Iteration 42 ----------------
Sampling trajectories from environment ...
Sampling spend time: 284.73748564720154s
Processing trajectories ...
Processing spend time: 553.8445026874542s
Baselien algorithms: 19.176000118255615s
Updating policies ....
Update spend time: 68.73130655288696s
-------------------------------------------
| Itr                     | 42            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1115.52      |
| batch size              | 160           |
| entropy loss:           | 1.5           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.01         |
| value loss:             | 15.19         |
-------------------------------------------

 ---------------- Iteration 43 ----------------
Sampling trajectories from environment ...
Sampling spend time: 283.06422448158264s
Processing trajectories ...
Processing spend time: 554.0802216529846s
Baselien algorithms: 19.15803074836731s
Updating policies ....
Update spend time: 69.04628944396973s
-------------------------------------------
| Itr                     | 43            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1121.59      |
| batch size              | 160           |
| entropy loss:           | 1.23          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.01         |
| value loss:             | 15.06         |
-------------------------------------------

 ---------------- Iteration 44 ----------------
Sampling trajectories from environment ...
Sampling spend time: 279.9579689502716s
Processing trajectories ...
Processing spend time: 555.307286977768s
Baselien algorithms: 19.206029653549194s
Updating policies ....
Update spend time: 69.36953330039978s
-------------------------------------------
| Itr                     | 44            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1117.17      |
| batch size              | 160           |
| entropy loss:           | 1.04          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.01         |
| value loss:             | 15.11         |
-------------------------------------------

 ---------------- Iteration 45 ----------------
Sampling trajectories from environment ...
Sampling spend time: 282.2399125099182s
Processing trajectories ...
Processing spend time: 552.2374279499054s
Baselien algorithms: 19.15610408782959s
Updating policies ....
Update spend time: 68.60009217262268s
-------------------------------------------
| Itr                     | 45            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1117.35      |
| batch size              | 160           |
| entropy loss:           | 0.86          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.25         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 46 ----------------
Sampling trajectories from environment ...
Sampling spend time: 284.94415521621704s
Processing trajectories ...
Processing spend time: 553.7886531352997s
Baselien algorithms: 19.161001205444336s
Updating policies ....
Update spend time: 69.82160091400146s
-------------------------------------------
| Itr                     | 46            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1117.58      |
| batch size              | 160           |
| entropy loss:           | 0.75          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.24         |
-------------------------------------------

 ---------------- Iteration 47 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.4876022338867s
Processing trajectories ...
Processing spend time: 553.5326793193817s
Baselien algorithms: 19.12596893310547s
Updating policies ....
Update spend time: 69.29080986976624s
-------------------------------------------
| Itr                     | 47            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1113.76      |
| batch size              | 160           |
| entropy loss:           | 0.67          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.13         |
-------------------------------------------

 ---------------- Iteration 48 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.5118305683136s
Processing trajectories ...
Processing spend time: 550.7707350254059s
Baselien algorithms: 19.222033500671387s
Updating policies ....
Update spend time: 68.54224300384521s
-------------------------------------------
| Itr                     | 48            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1119.3       |
| batch size              | 160           |
| entropy loss:           | 0.59          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.12         |
-------------------------------------------

 ---------------- Iteration 49 ----------------
Sampling trajectories from environment ...
Sampling spend time: 284.16358399391174s
Processing trajectories ...
Processing spend time: 554.1784930229187s
Baselien algorithms: 19.166030645370483s
Updating policies ....
Update spend time: 69.42257285118103s
-------------------------------------------
| Itr                     | 49            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1112.27      |
| batch size              | 160           |
| entropy loss:           | 0.49          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.2          |
-------------------------------------------

 ---------------- Iteration 50 ----------------
Sampling trajectories from environment ...
Sampling spend time: 282.1876482963562s
Processing trajectories ...
Processing spend time: 536.7312638759613s
Baselien algorithms: 18.98403835296631s
Updating policies ....
Update spend time: 65.42857456207275s
-------------------------------------------
| Itr                     | 50            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1113.86      |
| batch size              | 160           |
| entropy loss:           | 0.42          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.17         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 51 ----------------
Sampling trajectories from environment ...
Sampling spend time: 275.53679370880127s
Processing trajectories ...
Processing spend time: 535.5078570842743s
Baselien algorithms: 19.077457666397095s
Updating policies ....
Update spend time: 65.3868305683136s
-------------------------------------------
| Itr                     | 51            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1111.64      |
| batch size              | 160           |
| entropy loss:           | 0.36          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.1          |
-------------------------------------------

 ---------------- Iteration 52 ----------------
Sampling trajectories from environment ...
Sampling spend time: 280.6517233848572s
Processing trajectories ...
Processing spend time: 531.1001863479614s
Baselien algorithms: 19.091288805007935s
Updating policies ....
Update spend time: 66.80085897445679s
-------------------------------------------
| Itr                     | 52            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1115.28      |
| batch size              | 160           |
| entropy loss:           | 0.31          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.11         |
-------------------------------------------

 ---------------- Iteration 53 ----------------
Sampling trajectories from environment ...
Sampling spend time: 284.0741009712219s
Processing trajectories ...
Processing spend time: 565.4143061637878s
Baselien algorithms: 19.177552700042725s
Updating policies ....
Update spend time: 70.58316445350647s
-------------------------------------------
| Itr                     | 53            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1117.22      |
| batch size              | 160           |
| entropy loss:           | 0.28          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.35         |
-------------------------------------------

 ---------------- Iteration 54 ----------------
Sampling trajectories from environment ...
Sampling spend time: 285.9133791923523s
Processing trajectories ...
Processing spend time: 559.0752184391022s
Baselien algorithms: 19.14626908302307s
Updating policies ....
Update spend time: 69.43784022331238s
-------------------------------------------
| Itr                     | 54            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1114.79      |
| batch size              | 160           |
| entropy loss:           | 0.25          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.19         |
-------------------------------------------

 ---------------- Iteration 55 ----------------
Sampling trajectories from environment ...
Sampling spend time: 287.4602527618408s
Processing trajectories ...
Processing spend time: 556.5293629169464s
Baselien algorithms: 19.21716022491455s
Updating policies ....
Update spend time: 69.98044657707214s
-------------------------------------------
| Itr                     | 55            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1113.73      |
| batch size              | 160           |
| entropy loss:           | 0.23          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.17         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 56 ----------------
Sampling trajectories from environment ...
Sampling spend time: 287.8058023452759s
Processing trajectories ...
Processing spend time: 556.500411272049s
Baselien algorithms: 19.14099931716919s
Updating policies ....
Update spend time: 68.98856377601624s
-------------------------------------------
| Itr                     | 56            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1116.19      |
| batch size              | 160           |
| entropy loss:           | 0.22          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.09         |
-------------------------------------------

 ---------------- Iteration 57 ----------------
Sampling trajectories from environment ...
Sampling spend time: 285.27850461006165s
Processing trajectories ...
Processing spend time: 556.5666029453278s
Baselien algorithms: 19.103042125701904s
Updating policies ....
Update spend time: 69.19057822227478s
-------------------------------------------
| Itr                     | 57            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1117.09      |
| batch size              | 160           |
| entropy loss:           | 0.19          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.15         |
-------------------------------------------

 ---------------- Iteration 58 ----------------
Sampling trajectories from environment ...
Sampling spend time: 287.2044928073883s
Processing trajectories ...
Processing spend time: 551.532564163208s
Baselien algorithms: 19.130507469177246s
Updating policies ....
Update spend time: 68.52787113189697s
-------------------------------------------
| Itr                     | 58            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1111.21      |
| batch size              | 160           |
| entropy loss:           | 0.18          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.14         |
-------------------------------------------

 ---------------- Iteration 59 ----------------
Sampling trajectories from environment ...
Sampling spend time: 284.32724380493164s
Processing trajectories ...
Processing spend time: 554.3600840568542s
Baselien algorithms: 19.11951756477356s
Updating policies ....
Update spend time: 68.43036460876465s
-------------------------------------------
| Itr                     | 59            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1111.9       |
| batch size              | 160           |
| entropy loss:           | 0.21          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.11         |
-------------------------------------------

 ---------------- Iteration 60 ----------------
Sampling trajectories from environment ...
Sampling spend time: 287.3777108192444s
Processing trajectories ...
Processing spend time: 555.4130616188049s
Baselien algorithms: 19.15204906463623s
Updating policies ....
Update spend time: 68.98192691802979s
-------------------------------------------
| Itr                     | 60            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1110.46      |
| batch size              | 160           |
| entropy loss:           | 0.19          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.1          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 61 ----------------
Sampling trajectories from environment ...
Sampling spend time: 285.07026863098145s
Processing trajectories ...
Processing spend time: 551.5963461399078s
Baselien algorithms: 19.201157569885254s
Updating policies ....
Update spend time: 69.6382269859314s
-------------------------------------------
| Itr                     | 61            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1115.03      |
| batch size              | 160           |
| entropy loss:           | 0.18          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.08         |
-------------------------------------------

 ---------------- Iteration 62 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.9963707923889s
Processing trajectories ...
Processing spend time: 552.4253127574921s
Baselien algorithms: 19.13959789276123s
Updating policies ....
Update spend time: 68.89347887039185s
-------------------------------------------
| Itr                     | 62            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1111.87      |
| batch size              | 160           |
| entropy loss:           | 0.17          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.11         |
-------------------------------------------

 ---------------- Iteration 63 ----------------
Sampling trajectories from environment ...
Sampling spend time: 288.0399775505066s
Processing trajectories ...
Processing spend time: 552.6883397102356s
Baselien algorithms: 19.09608817100525s
Updating policies ....
Update spend time: 69.01464247703552s
-------------------------------------------
| Itr                     | 63            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1109.38      |
| batch size              | 160           |
| entropy loss:           | 0.16          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.06         |
-------------------------------------------

 ---------------- Iteration 64 ----------------
Sampling trajectories from environment ...
Sampling spend time: 288.0741140842438s
Processing trajectories ...
Processing spend time: 559.41090965271s
Baselien algorithms: 19.10814905166626s
Updating policies ....
Update spend time: 68.14408111572266s
-------------------------------------------
| Itr                     | 64            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1117.03      |
| batch size              | 160           |
| entropy loss:           | 0.16          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.14         |
-------------------------------------------

 ---------------- Iteration 65 ----------------
Sampling trajectories from environment ...
Sampling spend time: 288.35733103752136s
Processing trajectories ...
Processing spend time: 574.1124775409698s
Baselien algorithms: 19.669620037078857s
Updating policies ....
Update spend time: 73.15875053405762s
-------------------------------------------
| Itr                     | 65            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1109.62      |
| batch size              | 160           |
| entropy loss:           | 0.15          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.17         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 66 ----------------
Sampling trajectories from environment ...
Sampling spend time: 300.1240496635437s
Processing trajectories ...
Processing spend time: 561.8562123775482s
Baselien algorithms: 19.426653146743774s
Updating policies ....
Update spend time: 73.31197595596313s
-------------------------------------------
| Itr                     | 66            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1111.39      |
| batch size              | 160           |
| entropy loss:           | 0.15          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.16         |
-------------------------------------------

 ---------------- Iteration 67 ----------------
Sampling trajectories from environment ...
Sampling spend time: 308.7977194786072s
Processing trajectories ...
Processing spend time: 536.2982311248779s
Baselien algorithms: 19.113996982574463s
Updating policies ....
Update spend time: 67.07291460037231s
-------------------------------------------
| Itr                     | 67            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1113.59      |
| batch size              | 160           |
| entropy loss:           | 0.14          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.07         |
-------------------------------------------

 ---------------- Iteration 68 ----------------
Sampling trajectories from environment ...
Sampling spend time: 317.6100175380707s
Processing trajectories ...
Processing spend time: 544.3630692958832s
Baselien algorithms: 19.565608739852905s
Updating policies ....
Update spend time: 71.2463915348053s
-------------------------------------------
| Itr                     | 68            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1110.33      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.16         |
-------------------------------------------

 ---------------- Iteration 69 ----------------
Sampling trajectories from environment ...
Sampling spend time: 298.65466594696045s
Processing trajectories ...
Processing spend time: 568.9679455757141s
Baselien algorithms: 19.356253385543823s
Updating policies ....
Update spend time: 70.79156160354614s
-------------------------------------------
| Itr                     | 69            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1110.78      |
| batch size              | 160           |
| entropy loss:           | 0.12          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.06         |
-------------------------------------------

 ---------------- Iteration 70 ----------------
Sampling trajectories from environment ...
Sampling spend time: 313.756117105484s
Processing trajectories ...
Processing spend time: 597.3218488693237s
Baselien algorithms: 19.8025164604187s
Updating policies ....
Update spend time: 71.89175057411194s
-------------------------------------------
| Itr                     | 70            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1114.54      |
| batch size              | 160           |
| entropy loss:           | 0.12          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.08         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 71 ----------------
Sampling trajectories from environment ...
Sampling spend time: 309.10436844825745s
Processing trajectories ...
Processing spend time: 562.3209161758423s
Baselien algorithms: 19.28400683403015s
Updating policies ....
Update spend time: 69.9247350692749s
-------------------------------------------
| Itr                     | 71            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1114.45      |
| batch size              | 160           |
| entropy loss:           | 0.11          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.09         |
-------------------------------------------

 ---------------- Iteration 72 ----------------
Sampling trajectories from environment ...
Sampling spend time: 309.1990089416504s
Processing trajectories ...
Processing spend time: 560.8497734069824s
Baselien algorithms: 19.283303260803223s
Updating policies ....
Update spend time: 69.60274934768677s
-------------------------------------------
| Itr                     | 72            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1113.76      |
| batch size              | 160           |
| entropy loss:           | 0.1           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.1          |
-------------------------------------------

 ---------------- Iteration 73 ----------------
Sampling trajectories from environment ...
Sampling spend time: 304.1938257217407s
Processing trajectories ...
Processing spend time: 559.3099899291992s
Baselien algorithms: 19.21268129348755s
Updating policies ....
Update spend time: 69.36878609657288s
-------------------------------------------
| Itr                     | 73            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1113.35      |
| batch size              | 160           |
| entropy loss:           | 0.11          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.05         |
-------------------------------------------

 ---------------- Iteration 74 ----------------
Sampling trajectories from environment ...
Sampling spend time: 304.3144688606262s
Processing trajectories ...
Processing spend time: 558.823894739151s
Baselien algorithms: 19.07802963256836s
Updating policies ....
Update spend time: 69.25044631958008s
-------------------------------------------
| Itr                     | 74            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1115.59      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.09         |
-------------------------------------------

 ---------------- Iteration 75 ----------------
Sampling trajectories from environment ...
Sampling spend time: 284.5456895828247s
Processing trajectories ...
Processing spend time: 557.0888621807098s
Baselien algorithms: 19.307048320770264s
Updating policies ....
Update spend time: 71.58951449394226s
-------------------------------------------
| Itr                     | 75            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1118.08      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.08         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 76 ----------------
Sampling trajectories from environment ...
Sampling spend time: 288.0262784957886s
Processing trajectories ...
Processing spend time: 564.9788248538971s
Baselien algorithms: 19.21897029876709s
Updating policies ....
Update spend time: 70.88390612602234s
-------------------------------------------
| Itr                     | 76            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1113.99      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.05         |
-------------------------------------------

 ---------------- Iteration 77 ----------------
Sampling trajectories from environment ...
Sampling spend time: 293.86499309539795s
Processing trajectories ...
Processing spend time: 582.2240204811096s
Baselien algorithms: 19.952595472335815s
Updating policies ....
Update spend time: 75.02034330368042s
-------------------------------------------
| Itr                     | 77            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1115.69      |
| batch size              | 160           |
| entropy loss:           | 0.14          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.08         |
-------------------------------------------

 ---------------- Iteration 78 ----------------
Sampling trajectories from environment ...
Sampling spend time: 316.0353991985321s
Processing trajectories ...
Processing spend time: 560.9443125724792s
Baselien algorithms: 19.42899990081787s
Updating policies ....
Update spend time: 69.71373724937439s
-------------------------------------------
| Itr                     | 78            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1108.81      |
| batch size              | 160           |
| entropy loss:           | 0.14          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.11         |
-------------------------------------------

 ---------------- Iteration 79 ----------------
Sampling trajectories from environment ...
Sampling spend time: 290.5597698688507s
Processing trajectories ...
Processing spend time: 559.7109212875366s
Baselien algorithms: 19.22204065322876s
Updating policies ....
Update spend time: 69.51807594299316s
-------------------------------------------
| Itr                     | 79            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1111.39      |
| batch size              | 160           |
| entropy loss:           | 0.14          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.06         |
-------------------------------------------

 ---------------- Iteration 80 ----------------
Sampling trajectories from environment ...
Sampling spend time: 287.92057704925537s
Processing trajectories ...
Processing spend time: 557.3312072753906s
Baselien algorithms: 19.24311661720276s
Updating policies ....
Update spend time: 69.42773985862732s
-------------------------------------------
| Itr                     | 80            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1115.94      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.06         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 81 ----------------
Sampling trajectories from environment ...
Sampling spend time: 288.0849974155426s
Processing trajectories ...
Processing spend time: 555.9591748714447s
Baselien algorithms: 19.291046142578125s
Updating policies ....
Update spend time: 68.90021252632141s
-------------------------------------------
| Itr                     | 81            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1108.63      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.06         |
-------------------------------------------

 ---------------- Iteration 82 ----------------
Sampling trajectories from environment ...
Sampling spend time: 291.7407841682434s
Processing trajectories ...
Processing spend time: 568.8147010803223s
Baselien algorithms: 20.093703269958496s
Updating policies ....
Update spend time: 75.45144867897034s
-------------------------------------------
| Itr                     | 82            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1113.63      |
| batch size              | 160           |
| entropy loss:           | 0.12          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.11         |
-------------------------------------------

 ---------------- Iteration 83 ----------------
Sampling trajectories from environment ...
Sampling spend time: 332.71431255340576s
Processing trajectories ...
Processing spend time: 593.6023840904236s
Baselien algorithms: 19.11824107170105s
Updating policies ....
Update spend time: 67.10725283622742s
-------------------------------------------
| Itr                     | 83            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1117.06      |
| batch size              | 160           |
| entropy loss:           | 0.11          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.04         |
-------------------------------------------

 ---------------- Iteration 84 ----------------
Sampling trajectories from environment ...
Sampling spend time: 312.18897247314453s
Processing trajectories ...
Processing spend time: 535.5119650363922s
Baselien algorithms: 19.138445615768433s
Updating policies ....
Update spend time: 67.48612689971924s
-------------------------------------------
| Itr                     | 84            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1111.23      |
| batch size              | 160           |
| entropy loss:           | 0.11          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.18         |
-------------------------------------------

 ---------------- Iteration 85 ----------------
Sampling trajectories from environment ...
Sampling spend time: 310.1882441043854s
Processing trajectories ...
Processing spend time: 538.9604542255402s
Baselien algorithms: 19.084301710128784s
Updating policies ....
Update spend time: 67.64076566696167s
-------------------------------------------
| Itr                     | 85            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1111.48      |
| batch size              | 160           |
| entropy loss:           | 0.11          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.03         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 86 ----------------
Sampling trajectories from environment ...
Sampling spend time: 290.9576518535614s
Processing trajectories ...
Processing spend time: 531.51460313797s
Baselien algorithms: 19.0395929813385s
Updating policies ....
Update spend time: 66.42602491378784s
-------------------------------------------
| Itr                     | 86            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1116.14      |
| batch size              | 160           |
| entropy loss:           | 0.11          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.04         |
-------------------------------------------

 ---------------- Iteration 87 ----------------
Sampling trajectories from environment ...
Sampling spend time: 312.36449909210205s
Processing trajectories ...
Processing spend time: 525.8005502223969s
Baselien algorithms: 19.118202209472656s
Updating policies ....
Update spend time: 66.51554656028748s
-------------------------------------------
| Itr                     | 87            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1114.23      |
| batch size              | 160           |
| entropy loss:           | 0.1           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.07         |
-------------------------------------------

 ---------------- Iteration 88 ----------------
Sampling trajectories from environment ...
Sampling spend time: 311.5686857700348s
Processing trajectories ...
Processing spend time: 529.3797981739044s
Baselien algorithms: 19.020653009414673s
Updating policies ....
Update spend time: 66.1238021850586s
-------------------------------------------
| Itr                     | 88            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1117.08      |
| batch size              | 160           |
| entropy loss:           | 0.1           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.14         |
-------------------------------------------

 ---------------- Iteration 89 ----------------
Sampling trajectories from environment ...
Sampling spend time: 309.3365738391876s
Processing trajectories ...
Processing spend time: 527.8538227081299s
Baselien algorithms: 19.041000843048096s
Updating policies ....
Update spend time: 66.11631083488464s
-------------------------------------------
| Itr                     | 89            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1114.15      |
| batch size              | 160           |
| entropy loss:           | 0.1           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.01         |
-------------------------------------------

 ---------------- Iteration 90 ----------------
Sampling trajectories from environment ...
Sampling spend time: 307.6449770927429s
Processing trajectories ...
Processing spend time: 528.4421050548553s
Baselien algorithms: 19.20553731918335s
Updating policies ....
Update spend time: 66.46800708770752s
-------------------------------------------
| Itr                     | 90            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1114.95      |
| batch size              | 160           |
| entropy loss:           | 0.1           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.15         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 91 ----------------
Sampling trajectories from environment ...
Sampling spend time: 305.8033781051636s
Processing trajectories ...
Processing spend time: 528.9252107143402s
Baselien algorithms: 19.162147283554077s
Updating policies ....
Update spend time: 66.6184732913971s
-------------------------------------------
| Itr                     | 91            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1112.63      |
| batch size              | 160           |
| entropy loss:           | 0.1           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.02         |
-------------------------------------------

 ---------------- Iteration 92 ----------------
Sampling trajectories from environment ...
Sampling spend time: 304.40868043899536s
Processing trajectories ...
Processing spend time: 531.1959803104401s
Baselien algorithms: 19.0438289642334s
Updating policies ....
Update spend time: 66.5052227973938s
-------------------------------------------
| Itr                     | 92            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1111.79      |
| batch size              | 160           |
| entropy loss:           | 0.1           |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.17         |
-------------------------------------------

 ---------------- Iteration 93 ----------------
Sampling trajectories from environment ...
Sampling spend time: 310.0936644077301s
Processing trajectories ...
Processing spend time: 524.3998160362244s
Baselien algorithms: 18.912194967269897s
Updating policies ....
Update spend time: 65.61932349205017s
-------------------------------------------
| Itr                     | 93            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1115.05      |
| batch size              | 160           |
| entropy loss:           | 0.11          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.06         |
-------------------------------------------

 ---------------- Iteration 94 ----------------
Sampling trajectories from environment ...
Sampling spend time: 283.5599181652069s
Processing trajectories ...
Processing spend time: 524.722829580307s
Baselien algorithms: 19.000988245010376s
Updating policies ....
Update spend time: 65.8793294429779s
-------------------------------------------
| Itr                     | 94            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1111.72      |
| batch size              | 160           |
| entropy loss:           | 0.11          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.04         |
-------------------------------------------

 ---------------- Iteration 95 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.12970423698425s
Processing trajectories ...
Processing spend time: 526.127462387085s
Baselien algorithms: 18.972034215927124s
Updating policies ....
Update spend time: 65.60741686820984s
-------------------------------------------
| Itr                     | 95            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1112.69      |
| batch size              | 160           |
| entropy loss:           | 0.12          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.14         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 96 ----------------
Sampling trajectories from environment ...
Sampling spend time: 282.05575156211853s
Processing trajectories ...
Processing spend time: 526.410325050354s
Baselien algorithms: 18.974109649658203s
Updating policies ....
Update spend time: 65.32090520858765s
-------------------------------------------
| Itr                     | 96            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1110.65      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.02         |
-------------------------------------------

 ---------------- Iteration 97 ----------------
Sampling trajectories from environment ...
Sampling spend time: 279.60293912887573s
Processing trajectories ...
Processing spend time: 524.5360114574432s
Baselien algorithms: 18.922187089920044s
Updating policies ....
Update spend time: 65.45173454284668s
-------------------------------------------
| Itr                     | 97            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1115.16      |
| batch size              | 160           |
| entropy loss:           | 0.12          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.03         |
-------------------------------------------

 ---------------- Iteration 98 ----------------
Sampling trajectories from environment ...
Sampling spend time: 278.3548262119293s
Processing trajectories ...
Processing spend time: 525.5511786937714s
Baselien algorithms: 18.928380489349365s
Updating policies ....
Update spend time: 70.29177784919739s
-------------------------------------------
| Itr                     | 98            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1110.46      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.19         |
-------------------------------------------

 ---------------- Iteration 99 ----------------
Sampling trajectories from environment ...
Sampling spend time: 296.34779143333435s
Processing trajectories ...
Processing spend time: 555.6337578296661s
Baselien algorithms: 19.103970289230347s
Updating policies ....
Update spend time: 68.55770587921143s
-------------------------------------------
| Itr                     | 99            |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1114.96      |
| batch size              | 160           |
| entropy loss:           | 0.15          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 100 ----------------
Sampling trajectories from environment ...
Sampling spend time: 287.84254908561707s
Processing trajectories ...
Processing spend time: 556.8484342098236s
Baselien algorithms: 19.12803053855896s
Updating policies ....
Update spend time: 69.3592119216919s
-------------------------------------------
| Itr                     | 100           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1109.3       |
| batch size              | 160           |
| entropy loss:           | 0.15          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.0          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 101 ----------------
Sampling trajectories from environment ...
Sampling spend time: 283.84529161453247s
Processing trajectories ...
Processing spend time: 558.4467661380768s
Baselien algorithms: 19.156067848205566s
Updating policies ....
Update spend time: 69.12231278419495s
-------------------------------------------
| Itr                     | 101           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1115.61      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.04         |
-------------------------------------------

 ---------------- Iteration 102 ----------------
Sampling trajectories from environment ...
Sampling spend time: 289.3781678676605s
Processing trajectories ...
Processing spend time: 559.0660848617554s
Baselien algorithms: 19.26792621612549s
Updating policies ....
Update spend time: 68.69955515861511s
-------------------------------------------
| Itr                     | 102           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1110.61      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 14.96         |
-------------------------------------------

 ---------------- Iteration 103 ----------------
Sampling trajectories from environment ...
Sampling spend time: 288.01473331451416s
Processing trajectories ...
Processing spend time: 557.9818971157074s
Baselien algorithms: 19.146032094955444s
Updating policies ....
Update spend time: 68.83200144767761s
-------------------------------------------
| Itr                     | 103           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1118.03      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.02         |
-------------------------------------------

 ---------------- Iteration 104 ----------------
Sampling trajectories from environment ...
Sampling spend time: 284.92224192619324s
Processing trajectories ...
Processing spend time: 557.2155268192291s
Baselien algorithms: 19.10502862930298s
Updating policies ....
Update spend time: 68.84078073501587s
-------------------------------------------
| Itr                     | 104           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1110.12      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.04         |
-------------------------------------------

 ---------------- Iteration 105 ----------------
Sampling trajectories from environment ...
Sampling spend time: 282.52714228630066s
Processing trajectories ...
Processing spend time: 558.2231259346008s
Baselien algorithms: 19.239034414291382s
Updating policies ....
Update spend time: 69.22531318664551s
-------------------------------------------
| Itr                     | 105           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1116.06      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.0          |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 106 ----------------
Sampling trajectories from environment ...
Sampling spend time: 283.8412790298462s
Processing trajectories ...
Processing spend time: 556.8485927581787s
Baselien algorithms: 19.175000429153442s
Updating policies ....
Update spend time: 69.46091866493225s
-------------------------------------------
| Itr                     | 106           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1115.33      |
| batch size              | 160           |
| entropy loss:           | 0.14          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.03         |
-------------------------------------------

 ---------------- Iteration 107 ----------------
Sampling trajectories from environment ...
Sampling spend time: 284.51682472229004s
Processing trajectories ...
Processing spend time: 559.5966646671295s
Baselien algorithms: 19.209648370742798s
Updating policies ....
Update spend time: 69.62961292266846s
-------------------------------------------
| Itr                     | 107           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1111.14      |
| batch size              | 160           |
| entropy loss:           | 0.12          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.07         |
-------------------------------------------

 ---------------- Iteration 108 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.0161736011505s
Processing trajectories ...
Processing spend time: 559.1528799533844s
Baselien algorithms: 19.197693824768066s
Updating policies ....
Update spend time: 69.41983985900879s
-------------------------------------------
| Itr                     | 108           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1112.59      |
| batch size              | 160           |
| entropy loss:           | 0.12          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.06         |
-------------------------------------------

 ---------------- Iteration 109 ----------------
Sampling trajectories from environment ...
Sampling spend time: 285.44393849372864s
Processing trajectories ...
Processing spend time: 554.6512882709503s
Baselien algorithms: 19.130000352859497s
Updating policies ....
Update spend time: 69.31520867347717s
-------------------------------------------
| Itr                     | 109           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1117.33      |
| batch size              | 160           |
| entropy loss:           | 0.12          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.08         |
-------------------------------------------

 ---------------- Iteration 110 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.2809989452362s
Processing trajectories ...
Processing spend time: 556.4873414039612s
Baselien algorithms: 19.117059230804443s
Updating policies ....
Update spend time: 69.78045988082886s
-------------------------------------------
| Itr                     | 110           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1112.28      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 14.99         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 111 ----------------
Sampling trajectories from environment ...
Sampling spend time: 289.8449809551239s
Processing trajectories ...
Processing spend time: 559.5770227909088s
Baselien algorithms: 19.183992862701416s
Updating policies ....
Update spend time: 69.36861038208008s
-------------------------------------------
| Itr                     | 111           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1113.17      |
| batch size              | 160           |
| entropy loss:           | 0.14          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.02         |
-------------------------------------------

 ---------------- Iteration 112 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.14562726020813s
Processing trajectories ...
Processing spend time: 555.7316102981567s
Baselien algorithms: 19.143003702163696s
Updating policies ....
Update spend time: 69.52817153930664s
-------------------------------------------
| Itr                     | 112           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1119.69      |
| batch size              | 160           |
| entropy loss:           | 0.14          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.02         |
-------------------------------------------

 ---------------- Iteration 113 ----------------
Sampling trajectories from environment ...
Sampling spend time: 284.50834250450134s
Processing trajectories ...
Processing spend time: 556.416178226471s
Baselien algorithms: 19.125041007995605s
Updating policies ....
Update spend time: 68.62526106834412s
-------------------------------------------
| Itr                     | 113           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1115.41      |
| batch size              | 160           |
| entropy loss:           | 0.14          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 114 ----------------
Sampling trajectories from environment ...
Sampling spend time: 286.9771761894226s
Processing trajectories ...
Processing spend time: 558.2240796089172s
Baselien algorithms: 19.160067319869995s
Updating policies ....
Update spend time: 69.32960963249207s
-------------------------------------------
| Itr                     | 114           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1115.06      |
| batch size              | 160           |
| entropy loss:           | 0.14          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.0          |
-------------------------------------------

 ---------------- Iteration 115 ----------------
Sampling trajectories from environment ...
Sampling spend time: 282.98141527175903s
Processing trajectories ...
Processing spend time: 562.0346939563751s
Baselien algorithms: 19.213030576705933s
Updating policies ....
Update spend time: 69.62077927589417s
-------------------------------------------
| Itr                     | 115           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1116.07      |
| batch size              | 160           |
| entropy loss:           | 0.13          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 14.98         |
-------------------------------------------
save model weights ... 

 ---------------- Iteration 116 ----------------
Sampling trajectories from environment ...
Sampling spend time: 283.8127632141113s
Processing trajectories ...
Processing spend time: 555.3057882785797s
Baselien algorithms: 19.108052253723145s
Updating policies ....
Update spend time: 69.15866923332214s
-------------------------------------------
| Itr                     | 116           |
| average always migra... | -1.58e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1119.93      |
| batch size              | 160           |
| entropy loss:           | 0.15          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 14.98         |
-------------------------------------------

 ---------------- Iteration 117 ----------------
Sampling trajectories from environment ...
Sampling spend time: 287.84510922431946s
Processing trajectories ...
Processing spend time: 556.7067558765411s
Baselien algorithms: 19.162123441696167s
Updating policies ....
Update spend time: 69.17569422721863s
-------------------------------------------
| Itr                     | 117           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1116.07      |
| batch size              | 160           |
| entropy loss:           | 0.15          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 15.06         |
-------------------------------------------

 ---------------- Iteration 118 ----------------
Sampling trajectories from environment ...
Sampling spend time: 285.1476469039917s
Processing trajectories ...
Processing spend time: 553.7557542324066s
Baselien algorithms: 19.209483861923218s
Updating policies ....
Update spend time: 69.84926533699036s
-------------------------------------------
| Itr                     | 118           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1116.31      |
| batch size              | 160           |
| entropy loss:           | 0.16          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 14.97         |
-------------------------------------------

 ---------------- Iteration 119 ----------------
Sampling trajectories from environment ...
Sampling spend time: 283.7789931297302s
Processing trajectories ...
Processing spend time: 557.8109204769135s
Baselien algorithms: 19.156999588012695s
Updating policies ....
Update spend time: 68.46917176246643s
-------------------------------------------
| Itr                     | 119           |
| average always migra... | -1.59e+03     |
| average never migrat... | -1.5e+03      |
| average random reward:  | -2.27e+03     |
| average reward:         | -1114.02      |
| batch size              | 160           |
| entropy loss:           | 0.19          |
| optimal migrate rewa... | -0            |
| policy loss:            | -0.0          |
| value loss:             | 14.98         |
-------------------------------------------
